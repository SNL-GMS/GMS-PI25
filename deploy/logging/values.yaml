global:
  # baseDomain specifies the domain name suffix applied to all Ingress hostnames. Set by gmskube.
  baseDomain: "cluster.example.com"

  # basePort specifies the ingress port to access from outside the cluster. Set by gmskube.
  basePort: 443

  # env specifies environment variables that will be added to all applications
  # unless `useGlobalEnv: false` for that application
  env:

  # imagePullPolicy is the policy used for all images ('Always', 'IfNotPresent', 'Never').
  imagePullPolicy: "Always"

  # imageRegistry is the Docker image registry URL where all images will be retrieved. Set by gmskube.
  imageRegistry: "docker-registry.example.com"

  # imageTag is the Docker image tag used when retrieving all CI-built images. Set by gmskube.
  imageTag: "develop"

  # Whether or not to use istio. Set by gmskube.
  istio: false

  # Default PersistentVolumeClaim storage class.
  # Note that kafka's storageClass is configured independently, but it uses the default storage class
  # Empty uses the cluster's default storage class
  storageClassName:

  # Username of the user installing or upgrading the instance. Set by gmskube.
  user: "UNKNOWN"

  # Leave this set to false, kibana will still be included anyway. Setting it to true messes up how
  # the service names are rendered by the helm templates
  kibanaEnabled: false

# namespace LimitRange, can be a valid LimitRangeSpec yaml
limitRange:
  enabled: true
  limits:
  - defaultRequest:
      cpu: "10m"
      memory: "128Mi"
    default:
      memory: "500Mi"
    type: "Container"

# List of GMS standard apps. These are apps that use the common gms app templates.
# Note: an app definition must also be added in the section below for each standard app.
standardApps:
  - "elasticsearch-config"
  - "ldap-proxy"

# Secrets to copy from other namespaces
copySecrets:
  ingress-default-cert:
    namespace: "gms"
  ldap-bindpass:
    namespace: "gms"

# Configmaps to copy from other namespaces
copyConfigMaps:
  ldap-ca-cert:
    namespace: "gms"
  logging-ldap-proxy-config:
    namespace: "gms"


#
# App definitions
#
ldap-proxy:
  imageName: "gms-common/ldap_proxy"
  env:
    BIND_PASS:
      key: "bindpass"
      name: "ldap-bindpass"
      type: "fromSecret"
    LOG_LEVEL: "debug"
  network:
    ingress:
      8080:
        path: "/"
      host: "kibana.{{ .Values.global.baseDomain }}"
    service:
      8080:
        name: "http-web"
  resources:
    requests:
      cpu: "3m"
      memory: "125Mi"
    limits:
      memory: "200Mi"
  volume:
    ldap-ca-cert:
      configMapName: "ldap-ca-cert"
      mountPath: "/etc/config"
      type: "configMap"
    httpd-config:
      configMapName: "logging-ldap-proxy-config"
      mountPath: "/etc/httpd/conf.d"
      type: "configMap"

elasticsearch:
  coordinating:
    replicaCount: 0
  data:
    replicaCount: 0
  extraConfig:
    ingest:
      geoip:
        downloader:
          enabled: false #prevents es from trying to reach out to the internet
  fullnameOverride: "elasticsearch"
  image:
    repository: "gms-common/bitnami-elasticsearch"
    # tag: # set by gmskube
    pullPolicy: Always
  ingest:
    enabled: false
  ingress:
    enabled: true
    hostname: ""
    extraRules:
      - host: "elasticsearch.{{ .Values.global.baseDomain }}"
        http:
          paths:
            - path: "/"
              pathType: ImplementationSpecific
              backend:
                service:
                  name: elasticsearch
                  port:
                    name: tcp-rest-api
    extraTls:
      - hosts:
          - "elasticsearch.{{ .Values.global.baseDomain }}"
        secretName: ingress-default-cert
  kibana:
    elasticsearch:
      hosts:
        - elasticsearch
      port: 9200
    extraConfiguration:
      telemetry.optIn: false
      "uiSettings.overrides.theme:darkMode": true
    fullnameOverride: "logging-kibana"
    image:
      repository: "gms-common/bitnami-kibana"
      # tag: # set by gmskube
      pullPolicy: Always
    persistence:
      enabled: false
    resources:
      requests:
        cpu: "500m"
        memory: "1Gi"
      limits:
        cpu: "2"
        memory: "2300Mi"
    serviceAccount:
      create: false
      name: "gms"
  master:
    masterOnly: false
    replicaCount: 3
    resources:
      requests:
        cpu: "4000m"
        memory: "32Gi"
      limits:
        cpu: "4000m"
        memory: "32Gi"
    heapSize: 16g
    persistence:
      storageClass: "local-path"
      size: 300Gi
    serviceAccount:
      name: "gms"
    podAntiAffinityPreset: "soft"
    nodeAffinityPreset:
      type: "soft"
      key: "dedicated"
      values:
        - "elasticsearch"
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "elasticsearch"
        effect: "NoSchedule"
  sysctlImage:
    repository: gms-common/bitnami-elasticsearch
    # tag: # set by gmskube
    pullPolicy: Always

elasticsearch-config:
  command:
    - "/bin/bash"
    - "-c"
    - |
      #!/usr/bin/env bash

      # Define some common variables
      # Elastic search URL             - ES_URL
      # Default fluentd index          - FB_DEFAULT_INDEX
      # Rollover fluentd seed index    - FB_ROLLOVER_SEED_INDEX
      # Elasticsearch ILM policy       - ES_FB_ILM_POLICY
      # Elasticsearch index template   - ES_FB_INDEX_TEMPLATE
      # Elasticsearch fluentd alias    - ES_FB_INDEX_ALIAS
      # ----------------------------------------------------------------------------------------------

      ES_URL="http://elasticsearch:9200"
      FB_DEFAULT_INDEX="fluentd"
      FB_ROLLOVER_SEED_INDEX="fluentd-000001"
      ES_FB_ILM_POLICY="fluentd-policy"
      ES_FB_INDEX_TEMPLATE="fluentd-template"
      ES_FB_INDEX_ALIAS="fluentd"

      # Curl the elasticsearch URL and save the response
      curl_cmd="curl -s -o /dev/null -w '%{http_code}\n' $ES_URL/_cat/indices?v"
      #echo "curl_cmd:  $curl_cmd"
      RESP=$(eval "$curl_cmd")

      # If the response is NOT 200, then loop until it is 200
      if [[ "$RESP" != "200" ]]; then
          while [[ "$RESP" != "200" ]]; do
            echo "waiting for elastic search"
            sleep 1
            echo "curl_cmd:  $curl_cmd"
            RESP=$(eval "$curl_cmd")
          done
      else
          echo "elasticsearch is UP"
      fi

      # Check for the existence of an index named "fluentd" (only check for an index
      # with this name - NOT an alias).  This would be the default index generated by
      # fluentd (note, does NOT have a numeric suffix).  If this index exists,
      # we want to delete it (so we can create one with a numeric suffix)
      curl_cmd="curl -s $ES_URL/_cluster/state?filter_path=metadata.indices.$FB_DEFAULT_INDEX"
      echo "curl_cmd:  $curl_cmd"
      RESP=$(eval "$curl_cmd")
      echo "RESP:  $RESP"

      if [[ "$RESP" != "{}" ]]; then
          echo "$FB_DEFAULT_INDEX exists ... Delete it"
          curl_cmd="curl -s -o /dev/null -w '%{http_code}' -XDELETE $ES_URL/$FB_DEFAULT_INDEX"
          echo "curl_cmd:  $curl_cmd"
          RESP=$(eval "$curl_cmd")
          echo "RESP: $RESP"

          # Checking for RESP=200 is unreliable so we are just going to run the index
          # command again
          curl_cmd="curl -s $ES_URL/_cluster/state?filter_path=metadata.indices.$FB_DEFAULT_INDEX"
          echo "curl_cmd:  $curl_cmd"
          RESP=$(eval "$curl_cmd")
          echo "RESP:  $RESP"

          if [[ "$RESP" != "{}" ]]; then
            echo "ERROR:  The default fluentd index:  $FB_DEFAULT_INDEX exists but cannot be DELETED ... exiting"
            exit 1
          else
            echo "The default fluentd index:  $FB_DEFAULT_INDEX was SUCCESSFULLY DELETED"
          fi
      else
          echo "$FB_DEFAULT_INDEX does NOT exist ... continuing"
      fi

      # Check for the existence of the ILM (index lifecycle management) policy named "fluentd-policy".
      # If this index already exists, do nothing otherwise create it
      curl_cmd="curl -s -o /dev/null -w '%{http_code}' $ES_URL/_ilm/policy/$ES_FB_ILM_POLICY"
      echo "curl_cmd:  $curl_cmd"
      RESP=$(eval "$curl_cmd")
      echo "RESP:  $RESP"

      if [[ "$RESP" != "200" ]]; then
          # Create the policy
          echo "$ES_FB_ILM_POLICY does NOT exist ... Create it"
          curl_cmd="curl -s -o /dev/null -w '%{http_code}' -XPUT $ES_URL/_ilm/policy/$ES_FB_ILM_POLICY -H 'Content-Type: application/json' -d'{\"policy\": {\"phases\": {\"hot\": {\"min_age\": \"${HOT_PHASE_MIN_AGE}\", \"actions\": {\"rollover\": {\"max_size\": \"${HOT_PHASE_ACTIONS_ROLLOVER_MAX_SIZE}\", \"max_age\": \"${HOT_PHASE_ACTIONS_ROLLOVER_MAX_AGE}\"}, \"set_priority\": {\"priority\": ${HOT_PHASE_SET_PRIORITY_PRIORITY}}}},\"delete\": {\"min_age\": \"${DELETE_PHASE_MIN_AGE}\", \"actions\": {\"delete\": {\"delete_searchable_snapshot\": ${DELETE_PHASE_ACTIONS_DELETE_DELETE_SEARCHABLE_SNAPSHOT}}}}}}}'"
          echo "curl_cmd:  $curl_cmd"
          RESP=$(eval "$curl_cmd")
          echo "RESP:  $RESP"

          # Checking the response code from the PUT is unreliable so re-run the GET
          # to check for successful creation
          curl_cmd="curl -s -o /dev/null -w '%{http_code}' $ES_URL/_ilm/policy/$ES_FB_ILM_POLICY"
          echo "curl_cmd:  $curl_cmd"
          RESP=$(eval "$curl_cmd")
          echo "RESP:  $RESP"

          if [[ "$RESP" != "200" ]]; then
            echo "ERROR:  Unable to create the Index Lifecycle Management Policy:  $ES_FB_ILM_POLICY ... exiting"
            exit 1
          else
            echo "The ILM Policy:  $ES_FB_ILM_POLICY was SUCCESSFULLY CREATED"
          fi
      else
          echo "$ES_FB_ILM_POLICY ALREADY EXISTS ... continuing"
      fi

      # Check for the existence of the index template named "fluentd-template".
      # If this index already exists, do nothing otherwise create it
      curl_cmd="curl -s -o /dev/null -w '%{http_code}' $ES_URL/_index_template/$ES_FB_INDEX_TEMPLATE"
      echo "curl_cmd:  $curl_cmd"
      RESP=$(eval "$curl_cmd")
      echo "RESP:  $RESP"

      if [[ "$RESP" != "200" ]]; then
          # Create the template
          echo "$ES_FB_INDEX_TEMPLATE does NOT exist ... Create it"
          curl_cmd="curl -s -o /dev/null -w '%{http_code}' -XPUT $ES_URL/_index_template/$ES_FB_INDEX_TEMPLATE -H 'Content-Type: application/json' -d'{\"index_patterns\" : [\"fluentd-*\"], \"template\" : {\"settings\" : {\"index.mapping.total_fields.limit\" : 2000, \"number_of_shards\" : 3, \"number_of_replicas\" : 1, \"index.lifecycle.name\" : \"fluentd-policy\", \"index.lifecycle.rollover_alias\" : \"fluentd\", \"index.routing.rebalance.enable\" : \"all\", \"index.refresh_interval\" : \"10s\"}}}'"
          echo "curl_cmd:  $curl_cmd"
          RESP=$(eval "$curl_cmd")
          echo "RESP:  $RESP"

          # Checking the response code from the PUT is unreliable so re-run the GET
          # to check for successful creation
          curl_cmd="curl -s -o /dev/null -w '%{http_code}' $ES_URL/_index_template/$ES_FB_INDEX_TEMPLATE"
          echo "curl_cmd:  $curl_cmd"
          RESP=$(eval "$curl_cmd")
          echo "RESP:  $RESP"

          if [[ "$RESP" != "200" ]]; then
            echo "ERROR:  Unable to create the Elasticsearch Index Template:  $ES_FB_INDEX_TEMPLATE ... exiting"
            exit 1
          else
            echo "The Index Template:  $ES_FB_INDEX_TEMPLATE was SUCCESSFULLY CREATED"
          fi
      else
          echo "$ES_FB_INDEX_TEMPLATE ALREADY EXISTS ... continuing"
      fi

      # Check for the existence of an index with a suffix such as "fluentd-000001"
      # If this index already exists, do nothing otherwise create it.  Use reg-ex
      # to figure out if the index exists and if so what it's name is
      curl_cmd="curl -s $ES_URL/$ES_FB_INDEX_ALIAS"
      echo "curl_cmd:  $curl_cmd"
      RESP=$(eval "$curl_cmd")
      echo "RESP:  $RESP"

      # Define regular exprssion that looks for a certain response to indicate there is
      # an suffixed index configured.
      # We need a pattern that will find "{"fluentd-00000n":{"aliases":{"fluentd":{"is_write_index":true}}
      # somewhere in the response (either at the beginning or somewhere buried in the response
      pattern="\{.*\"(fluentd-[0-9]+)\":\{\"aliases\":\{\"fluentd\":\{\"is_write_index\":true\}"

      # Check for a match on pattern
      if [[ $RESP =~ $pattern ]]
      then
          index_name="${BASH_REMATCH[1]}"
          echo "Rollover index_name:  $index_name exists ... continuing"
      else
          # Create the rollover suffixed index
          echo "$FB_ROLLOVER_SEED_INDEX does NOT exist ... Create it"
          curl_cmd="curl -s -o /dev/null -w '%{http_code}' -XPUT $ES_URL/$FB_ROLLOVER_SEED_INDEX -H 'Content-Type: application/json' -d'{\"aliases\" : {\"fluentd\" : {\"is_write_index\" : true}}}'"
          echo "curl_cmd:  $curl_cmd"
          RESP=$(eval "$curl_cmd")
          echo "RESP:  $RESP"

          # Checking the response code from the PUT is unreliable so run a GET
          # to check for successful creation of the seed index
          curl_cmd="curl -s -o /dev/null -w '%{http_code}' $ES_URL/$FB_ROLLOVER_SEED_INDEX"
          echo "curl_cmd:  $curl_cmd"
          RESP=$(eval "$curl_cmd")
          echo "RESP:  $RESP"

          if [[ "$RESP" != "200" ]]; then
            echo "ERROR:  Unable to create the Elasticsearch fluentd Rollover Index:  $FB_ROLLOVER_SEED_INDEX ... exiting"
            exit 1
          else
            echo "The Elasticsearch fluentd Rollover Index:  $FB_ROLLOEVER_SEED_INDEX was SUCCESSFULLY CREATED"
          fi
      fi

      echo
      echo "elasticsearch has been SUCCESSFULLY initialized for fluentd ... start fluentd now"
  env:
    HOT_PHASE_MIN_AGE: "1d"
    HOT_PHASE_ACTIONS_ROLLOVER_MAX_AGE: "1d"
    HOT_PHASE_ACTIONS_ROLLOVER_MAX_SIZE: "30gb"
    HOT_PHASE_SET_PRIORITY_PRIORITY: "100"
    DELETE_PHASE_MIN_AGE: "7d"
    DELETE_PHASE_ACTIONS_DELETE_DELETE_SEARCHABLE_SNAPSHOT: "true"
  imageName: "gms-common/ubi"
  jobAnnotations:
    helm.sh/hook: "post-install,post-upgrade"
    helm.sh/hook-delete-policy: "before-hook-creation"
  kind: "job"
  resources:
    requests:
      cpu: "1m"
      memory: "1Mi"
    limits:
      memory: "50Mi"
  restartPolicy: "OnFailure"
  terminationGracePeriodSeconds: 0
  ttlSecondsAfterFinished: 300

fluentd:
  image:
    repository: "" # set by gmskube
    pullPolicy: "Always"
    tag: "" # set by gmskube

  env:
    - name: "CLUSTER_NAME"
      value: "{{ .Values.global.baseDomain }}"

  initContainers:
    - name: wait-for-es-index
      image: "{{ .Values.global.imageRegistry }}/gms-common/ubi:{{ .Values.global.imageTag | trunc 63 }}"
      imagePullPolicy: Always
      command:
        - "/bin/bash"
        - "-c"
        - |
          #!/usr/bin/env bash

          ES_URL="http://elasticsearch:9200"
          ES_FB_INDEX_ALIAS="fluentd"

          # Check for the existence of an index with a suffix such as "fluentd-000001"
          # If this index already exists, do nothing otherwise create it.  Use reg-ex
          # to figure out if the index exists and if so what it's name is
          curl_cmd="curl -s $ES_URL/$ES_FB_INDEX_ALIAS"
          echo "curl_cmd:  $curl_cmd"
          RESP=$(eval "$curl_cmd")
          echo "RESP:  $RESP"

          # Define regular exprssion that looks for a certain response to indicate there is a suffixed index configured
          # We need a pattern that will find "{"fluentd-00000n":{"aliases":{"fluentd":{"is_write_index":true}}
          # somewhere in the response (either at the beginning or somewhere buried in the response
          pattern="\{.*\"(fluentd-[0-9]+)\":\{\"aliases\":\{\"fluentd\":\{\"is_write_index\":true\}"

          # Check for a match on pattern
          if [[ ! $RESP =~ $pattern ]]; then
              while [[ ! $RESP =~ $pattern ]]; do
                  echo "waiting for index creation"
                  sleep 10
                  RESP=$(eval "$curl_cmd")
              done
          else
              index_name="${BASH_REMATCH[1]}"
              echo "Rollover index_name:  $index_name exists ... continuing"
          fi

          echo
          echo "elasticsearch has been SUCCESSFULLY initialized for fluentd ... start fluentd now"
      securityContext:
        allowPrivilegeEscalation: false
        runAsNonRoot: true
        runAsUser: 1001

  # fluentd daemonset doesn't deploy with istio
  podAnnotations:
    sidecar.istio.io/inject: "false"

  podSecurityContext:
    seLinuxOptions:
      type: "spc_t"
    runAsNonRoot: true

  resources:
    requests:
      cpu: 50m
      memory: 400Mi
  limits:
    memory: 800Mi

  securityContext:
    runAsNonRoot: false
    runAsUser: 0
    allowPrivilegeEscalation: false

  # some volumes are mounted automatically by the chart
  volumes:
  - name: datadockercontainers
    hostPath:
      path: /data/docker/containers

  volumeMounts:
  - name: datadockercontainers
    mountPath: /data/docker/containers

  configMapConfigs:
    - fluentd-prometheus-conf

  ## Fluentd configurations:
  ##
  fileConfigs:
    01_sources.conf: |-
      <source>
        @type tail
        @id in_tail_container_logs
        @label @CONCAT
        path /var/log/containers/*.log
        pos_file /var/log/fluentd-containers.log.pos
        tag kubernetes.*
        exclude_path ["/var/log/containers/fluent*"]
        read_from_head true
        <parse>
          @type regexp
          expression /^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$/
          time_format "%Y-%m-%dT%H:%M:%S.%N%:z"
          time_key time
          keep_time_key true
          time_type string
        </parse>
        emit_unmatched_lines true
      </source>

    02_filters.conf: |-
      <label @CONCAT>
        <match kubernetes.var.log.containers.fluentd**>
          @type relabel
          @label @FLUENT_LOG
        </match>

        # This filter concatenates split logs
        <filter kubernetes.**>
          @type concat
          key log
          use_partial_cri_logtag true
          partial_cri_logtag_key logtag
          partial_cri_stream_key stream
        </filter>

        # This filter renames the "log" key to "appLog"
        <filter kubernetes.**>
          @type parser
          key_name log
          reserve_data true
          reserve_time true
          hash_value_field appLog
          remove_key_name_field true
          replace_invalid_sequence true
          emit_invalid_record_to_error false
          <parse>
            @type json
          </parse>
        </filter>

        # This filter add kubernetes meta data to each record
        <filter kubernetes.**>
          @type kubernetes_metadata
          @id filter_kube_metadata
          skip_labels false
          skip_container_metadata false
          skip_namespace_metadata true
          skip_master_url true
        </filter>

        # This filter adds a new field cluster using an env var
        <filter kubernetes.**>
          @type record_transformer
          <record>
            cluster "#{ENV["CLUSTER_NAME"]}"
          </record>
        </filter>

        <match **>
          @type relabel
          @label @OUTPUT
        </match>
      </label>

    04_outputs.conf: |-
      <label @OUTPUT>
        <match **>
          #@type file
          #path /data/FLUENTD-scraped-logs
          # ---------------------------------------------------
          # This match outputs the logs to elasticsearch
          @type elasticsearch
          host "elasticsearch"
          port 9200
          # ---------------------------------------------------
          logstash_format false
          index_name fluentd
          type_name fluentd
          include_timestamp true
          #<buffer>
          #  @type file
          #  path /fluentd/log/elastic-buffer
          #  flush_thread_count 16
          #  flush_interval 1s
          #  chunk_limit_size 512M
          #  flush_mode interval
          #  retry_forever true
          #  total_limit_size 256G
          #</buffer>
          <buffer>
            @type file
            path '/var/lib/fluentd/default'
            flush_mode interval
            flush_interval 5s
            flush_thread_count 3
            retry_type periodic
            retry_wait 1s
            retry_max_interval 300s
            retry_timeout 60m
            total_limit_size 32m
            chunk_limit_size 8m
            overflow_action throw_exception
          </buffer>
        </match>
      </label>
